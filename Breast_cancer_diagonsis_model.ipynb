{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1qthQyrw0Yc9"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os, shutil, pathlib, glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "SEED = 4747\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are uploading the kaggle json file to faciliate the process of obtaining the dataset of histopathological images"
      ],
      "metadata": {
        "id": "IywZI_DU1Vkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "iuTuBdnj08IU",
        "outputId": "44b856f1-53db-443e-96cb-191fb4d21b8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6320c60b-58ee-4f94-a5b5-3b3e24d0f293\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6320c60b-58ee-4f94-a5b5-3b3e24d0f293\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"bluekingnfx\",\"key\":\"a50380852bb480d73c7f7e43389358c7\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing Kaggle directory in google collab and moving the json into the kaggle folder to install dataset"
      ],
      "metadata": {
        "id": "QzY5_oXZ1wXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create \"~/.kaggle\" directory\n",
        "!mkdir ~/.kaggle\n",
        "\n",
        "#Move \"kaggle.json\" file to this directory\n",
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "VeAK7xnK1GvS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving the write access to the folder created in linux os of google collab hosted in cloud"
      ],
      "metadata": {
        "id": "e0RnLNzJ2IYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Rh6OmS8e2IHn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the dataset with API command"
      ],
      "metadata": {
        "id": "KTfxMuOd2q6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sEpaotV2o8v",
        "outputId": "a8e99802-1d22-4864-e5c3-db0ce430644d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading breast-histopathology-images.zip to /content\n",
            "100% 3.10G/3.10G [01:31<00:00, 41.3MB/s]\n",
            "100% 3.10G/3.10G [01:31<00:00, 36.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "774dJbnK2GmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a directory \"dataset\" to unzip the file there"
      ],
      "metadata": {
        "id": "NgQ1PyR8250-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Ay7D3p25IT",
        "outputId": "2f78ebac-1cea-4e51-f82e-4403a6dff6c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "breast-histopathology-images.zip  dataset  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unziping the dataset"
      ],
      "metadata": {
        "id": "NWWmh4z73Xuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/breast-histopathology-images.zip\" -d \"/content/dataset\""
      ],
      "metadata": {
        "id": "aVle38MD3XMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total directories (that is, total number of patients)"
      ],
      "metadata": {
        "id": "7Q9C8xbd35vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirs = os.listdir(\"/content/dataset/\")\n",
        "print(\"Total number of directories are =\",len(dirs))"
      ],
      "metadata": {
        "id": "dOMO-22X3oqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset assigns a unique filename structure to each image, like:\n",
        "```\n",
        "u_xX_yY_classC.png\n",
        "\n",
        "```\n",
        "For example:\n",
        "```\n",
        "10253_idx5_x1351_y1101_class0.png\n",
        "```\n",
        "\n",
        "- \"u\" is patient id\n",
        "- \"u\" is the patient ID (10253_idx5),\n",
        "- \"X\" is the x-coordinate of where this patch was cropped from,\n",
        "- \"Y\" is the y-coordinate of where this patch was cropped from, and\n",
        "- \"C\" indicates the class where 0 is non-IDC and 1 is IDC."
      ],
      "metadata": {
        "id": "emnf0_164CCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_random_patches(clas):\n",
        "    fig, axes = plt.subplots(7,7,figsize=(10,10))\n",
        "    for ax in axes.flatten():\n",
        "        #Get a random patient id\n",
        "        patient_id = random.choice(dirs)\n",
        "\n",
        "        path = f\"/content/dataset/{patient_id}/{clas}/*.png\"\n",
        "        #Read all the files' path present in \"path\" directory\n",
        "        paths = glob.glob(path)\n",
        "        #Select a random file path\n",
        "        p = random.choice(paths)\n",
        "        #Get the path with semantics appropriate for underlying OS\n",
        "        p = pathlib.Path(p)\n",
        "        #Load the image\n",
        "        img = load_img(p)\n",
        "        #Plot theimage\n",
        "        ax.imshow(img)\n",
        "        #Set image properties\n",
        "        ax.set_title(label=patient_id, fontdict={\"fontsize\":8})\n",
        "        ax.tick_params(left = False, right = False , labelleft = False ,\n",
        "                labelbottom = False, bottom = False)\n",
        "\n",
        "    #Use different image title for cancer and normal tissues\n",
        "    if clas == 1:\n",
        "        fig.suptitle('IDC+ patches\\n(Cancer tissues)', fontsize=16)\n",
        "    else:\n",
        "        fig.suptitle('IDC- patches\\n(Noraml tissues)', fontsize=16)"
      ],
      "metadata": {
        "id": "BNh05G8o3j9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot random images of IDC+ / cancer tissues"
      ],
      "metadata": {
        "id": "x9pNbLsD4T6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_random_patches(clas=1)"
      ],
      "metadata": {
        "id": "9wMeXIim4Rtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The core functionality: For each paitent (directory)\n",
        "thier corresponding 0 and 1 samples are seggregated and randomized,\n",
        "then the classes for each iteration is extended to main arrays of class_0, class_1\n",
        "This function is built to improve random sampling.\n",
        "\"\"\"\n",
        "\n",
        "def get_image_path_list():\n",
        "    #Create empty lists to store the paths of class 0 and class 1 images\n",
        "    class_0 = []\n",
        "    class_1 = []\n",
        "    for dir in dirs:\n",
        "        #Read class 0 and class 1 images' paths for a given patient\n",
        "        # and store them it their respective list\n",
        "        c_0 = glob.glob(f\"/content/dataset/{dir}/0/*.png\")\n",
        "        c_1 = glob.glob(f\"/content/dataset/{dir}/1/*.png\")\n",
        "\n",
        "        random.shuffle(c_0)\n",
        "        random.shuffle(c_1)\n",
        "\n",
        "        #Add the class 0 and class 1 images' paths for a given patient\n",
        "        # to the main list\n",
        "        class_0.extend(c_0)\n",
        "        class_1.extend(c_1)\n",
        "\n",
        "        random.shuffle(class_0)\n",
        "        random.shuffle(class_1)\n",
        "\n",
        "    #Shuffle the paths lists randomly\n",
        "    random.shuffle(class_0), random.shuffle(class_0)\n",
        "    random.shuffle(class_1), random.shuffle(class_1)\n",
        "\n",
        "    #Return the class_0 and class_1 lists\n",
        "    return class_0, class_1"
      ],
      "metadata": {
        "id": "G8-ce0GuJBXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Core functionality is to create a train and test directory under the new_dataset main directory,\n",
        "the seggregation of the image files of specific class is defined by specific threshold value,\n",
        "default in create_dataset function, about 80% of data is used for training.\n",
        "\n",
        "'''\n",
        "\n",
        "def create_dataset(train_split=0.80):\n",
        "\n",
        "    train0_dir = \"/content/new_dataset/train/0\"\n",
        "    train1_dir = \"/content/new_dataset/train/1\"\n",
        "    os.makedirs(train0_dir)\n",
        "    os.mkdir(train1_dir)\n",
        "\n",
        "    test0_dir = \"/content/new_dataset/test/0\"\n",
        "    test1_dir = \"/content/new_dataset/test/1\"\n",
        "    os.makedirs(test0_dir)\n",
        "    os.mkdir(test1_dir)\n",
        "\n",
        "    class0, class1 = get_image_path_list()\n",
        "\n",
        "    random.shuffle(class0)\n",
        "    random.shuffle(class1)\n",
        "\n",
        "    total_img0 = len(class0)\n",
        "    total_img1 = len(class1)\n",
        "\n",
        "    train0_thresh = int(total_img0 * train_split)\n",
        "    train1_thresh = int(total_img1 * train_split)\n",
        "\n",
        "    for i in range(total_img0):\n",
        "        path = class0[i]\n",
        "        if i < train0_thresh:\n",
        "            shutil.copy(src=path, dst= train0_dir)\n",
        "        else:\n",
        "            shutil.copy(src=path, dst= test0_dir)\n",
        "\n",
        "    for i in range(total_img1):\n",
        "        path = class1[i]\n",
        "        if i < train1_thresh:\n",
        "            shutil.copy(src=path, dst= train1_dir)\n",
        "        else:\n",
        "            shutil.copy(src=path, dst= test1_dir)"
      ],
      "metadata": {
        "id": "ofwWntyCQUM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dataset()"
      ],
      "metadata": {
        "id": "ndbMm7AWRunR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checkpoint: We new_dataset directory of structure train and test sub directory, this indeed contains 0 and 1 directory of 0 and 1 images. Train: 80% data, test: 20%."
      ],
      "metadata": {
        "id": "cRXiVDKrSDY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class0, class1 = get_image_path_list()\n",
        "\n",
        "print(\"80% images of class 0 =\", int(len(class0)*0.80))\n",
        "print(\"80% images in class 1 =\", int(len(class1)*0.80))\n",
        "\n",
        "train_data_size = glob.glob(\"/content/new_dataset/train/**/*.png\")\n",
        "print(\"Training dataset size =\",len(train_data_size))"
      ],
      "metadata": {
        "id": "0wO5PUuvSjEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image_dataset_from directory helps to create a image dataset from class labels infered from the subdirectories, image_size is resized to 50x50 and 32 images are processed once.\n",
        "\n",
        "Subnet argument in validation_dataset is used to return all the images that were ommited in training dataset to validation dataset"
      ],
      "metadata": {
        "id": "smtEk8hLVxwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (50,50)\n",
        "batch_size = 32\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    \"/content/new_dataset/train\",\n",
        "    labels = \"inferred\",\n",
        "    label_mode = 'int',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "\n",
        "validation_dataset =image_dataset_from_directory(\n",
        "    \"/content/new_dataset/train\",\n",
        "    labels = \"inferred\",\n",
        "    label_mode = 'int',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=SEED,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "ZdF1e8N5T79N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same process is carried for testing dataset without subnetting"
      ],
      "metadata": {
        "id": "VSol6r74WGum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = image_dataset_from_directory(\n",
        "    \"/content/new_dataset/test\",\n",
        "    labels = \"inferred\",\n",
        "    label_mode = 'int',\n",
        "    seed=SEED,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "LjsVchV4V-1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since neural networks should consume lot of images to cover up/recoginize, since over dataset of training is just 2 lakhs+ it is minimal, this tend to make the model more or less overfit, to overcome this, we going to use data augmentation and dropout layer techniques.\n",
        "\n",
        "Data agumentation - Is the process of creating additional images by resizing and magnizing the already existing images, there by increasing the size of the exisiting dataset\n",
        "\n",
        "Dropout layer - Disabling certain nodal layers to combat the team effect, putting more burdern certain layers to have a significant effect."
      ],
      "metadata": {
        "id": "bH9CiabtYAX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For modeling, the keras sequential architure is utilized, Pulling in layers required to form a neural network of own."
      ],
      "metadata": {
        "id": "cLr_ed9oaEBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combat overfitting"
      ],
      "metadata": {
        "id": "7y9flPMAbA_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(50, 50, 3))\n",
        "x = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.3),\n",
        "        layers.RandomZoom(0.3)\n",
        "    ]\n",
        ")(inputs)\n",
        "x = layers.Rescaling(1./255)(x)"
      ],
      "metadata": {
        "id": "JMgoS2oiX8-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conventions\n",
        "- Going to use the generally used architecture,\n",
        "Convultional neural layer -> Batch normalization -> Activation -> pooling\n",
        "\n",
        "Neural set to identify of 256 filters/features initally, larger number because smaller dimension of the image.\n",
        "Batch normalization, normalizing the input and activating the nodes\n",
        "\n",
        "Pooling -> Amplifing the patterns/features\n",
        "\n",
        "Three layers same process flow to improve better recoginization. Only 3 cause of computational cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bg1P0ZBkcWCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Conv2D(filters=256, kernel_size=3, use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, use_bias=False)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)"
      ],
      "metadata": {
        "id": "qIOp8HCibGQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatting the multi-dimension vector to single dimensional, passed to dense layer (fully connected NN) and to the output layer assigns 0 or 1"
      ],
      "metadata": {
        "id": "mTcmOarHmXJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n"
      ],
      "metadata": {
        "id": "opXy5AzSmWkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to input and output layer"
      ],
      "metadata": {
        "id": "xRDMTF0BnX7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "hnCY__Rtna_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "0VY6kw0znfzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "input_2: The input image layer taking images of shape (50, 50, 3)\n",
        "\n",
        "sequential_1: Empty sequential model, does nothing\n",
        "rescaling_1: Rescales input pixels from 0-255 to 0-1.\n",
        "\n",
        "conv2d_4: 2D Convolution layer with 256 filters of kernel size 3\n",
        "\n",
        "batch_normalization_4: Normalizes activations from conv layer\n",
        "\n",
        "activation_4: ReLU activation function\n",
        "\n",
        "conv2d_5, batch_normalization_5 etc: Repeats convolution, batch norm, activation blocks.\n",
        "\n",
        "max_pooling2d_3: Max pooling to downsample spatially by half.\n",
        "\n",
        "flatten_1: Flattens final conv feature maps to 1D vector\n",
        "\n",
        "dropout_1: Applies dropout regularization\n",
        "\n",
        "dense_4, dense_5 etc: Fully connected layers outputting class predictions."
      ],
      "metadata": {
        "id": "cNvyjEvdoK0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total number of edges in the neural network are about 39lakhish and on - trainable params are of 2048 contributed by normalization layers."
      ],
      "metadata": {
        "id": "AF3ZQkHxoSR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling before training,\n",
        "\n",
        "Telling model what things must be used,\n",
        "\n",
        "loss function is to binary_crossentropy -> assigning 0 or 1\n",
        "optimizer - Update weights during training\n",
        "\n",
        "metrices - To been considered while training"
      ],
      "metadata": {
        "id": "9muHSpX1pi3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=\"rmsprop\",\n",
        "               metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dxCdeYHDpf_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopping condition when to save the model\n"
      ],
      "metadata": {
        "id": "p-6hIAtaqv_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "            keras.callbacks.ModelCheckpoint(filepath=\"model.keras\",\n",
        "                                            save_best_only=True,\n",
        "                                            monitor=\"val_loss\")\n",
        "            ]"
      ],
      "metadata": {
        "id": "vl99HifmqvvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "J_kETkwMrKAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = model.fit(\n",
        "                    train_dataset,\n",
        "                    epochs=4,\n",
        "                    validation_data=validation_dataset,\n",
        "                    callbacks=callbacks\n",
        "                   )"
      ],
      "metadata": {
        "id": "9NplCdBhrHRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\"/content/CanDetect.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "84eU5V8nsDLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}